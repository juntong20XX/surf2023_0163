@inproceedings{defossez2021hybrid,
  title={Hybrid Spectrogram and Waveform Source Separation},
  author={D{\'e}fossez, Alexandre},
  booktitle={Proceedings of the ISMIR 2021 Workshop on Music Source Separation},
  year={2021}
}

@misc{kuielab,
  doi = {10.48550/ARXIV.2111.12203},
  
  url = {https://arxiv.org/abs/2111.12203},
  
  author = {Kim, Minseok and Choi, Woosung and Chung, Jaehwa and Lee, Daewon and Jung, Soonyoung},
  
  keywords = {Audio and Speech Processing (eess.AS), Sound (cs.SD), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {KUIELab-MDX-Net: A Two-Stream Neural Network for Music Demixing},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{demucsv2,
  doi = {10.48550/ARXIV.1911.13254},
  
  url = {https://arxiv.org/abs/1911.13254},
  
  author = {Défossez, Alexandre and Usunier, Nicolas and Bottou, Léon and Bach, Francis},
  
  keywords = {Sound (cs.SD), Machine Learning (cs.LG), Audio and Speech Processing (eess.AS), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {Music Source Separation in the Waveform Domain},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{d3net,
  doi = {10.48550/ARXIV.2010.01733},
  
  url = {https://arxiv.org/abs/2010.01733},
  
  author = {Takahashi, Naoya and Mitsufuji, Yuki},
  
  keywords = {Audio and Speech Processing (eess.AS), Machine Learning (cs.LG), Sound (cs.SD), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {D3Net: Densely connected multidilated DenseNet for music source separation},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{spleeter,
author = {Hennequin, Romain and Khlif, Anis and Voituret, Felix and Moussallam, Manuel},
year = {2020},
title = {Spleeter: a fast and efficient music source separation tool with pre-trained models},
journal = {Journal of Open Source Software},
doi = {10.21105/joss.02154}
}

@misc{musdb18-hq,
  author       = {Rafii, Zafar and
                  Liutkus, Antoine and
                  Stöter, Fabian-Robert and
                  Mimilakis, Stylianos Ioannis and
                  Bittner, Rachel},
  title        = {MUSDB18-HQ - an uncompressed version of MUSDB18},
  month        = aug,
  year         = 2019,
  doi          = {10.5281/zenodo.3338373},
  url          = {https://doi.org/10.5281/zenodo.3338373}
}

@misc{musdb,
  author       = {Rafii, Zafar and
                  Liutkus, Antoine and
                  Fabian-Robert Stöter and
                  Mimilakis, Stylianos Ioannis and
                  Bittner, Rachel},
  title        = {The MUSDB18 corpus for music separation},
  year         = 2017,
}

@misc{bsrnn,
      title={Music Source Separation with Band-split RNN}, 
      author={Yi Luo and Jianwei Yu},
      year={2022},
      eprint={2209.15174},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@inproceedings{layerscale,
  title={Going deeper with image transformers},
  author={Touvron, Hugo and Cord, Matthieu and Sablayrolles, Alexandre and Synnaeve, Gabriel and J{\'e}gou, Herv{\'e}},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2021}
}

@misc{sisec18,
      title={The 2018 Signal Separation Evaluation Campaign}, 
      author={Fabian-Robert Stöter and Antoine Liutkus and Nobutaka Ito},
      year={2018},
      eprint={1804.06267},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@inproceedings{sisec15,
  TITLE = {{The 2015 Signal Separation Evaluation Campaign}},
  AUTHOR = {Ono, Nobutaka and Rafii, Zafar and Kitamura, Daichi and Ito, Nobutaka and Liutkus, Antoine},
  URL = {https://hal.inria.fr/hal-01188725},
  BOOKTITLE = {{International Conference on Latent Variable Analysis and Signal Separation  (LVA/ICA)}},
  YEAR = {2015},
  MONTH = Aug,
  DOI = {10.1007/978-3-319-22482-4\_45},
  PDF = {https://hal.inria.fr/hal-01188725/file/LVA-ICA2015_055_original_v1.pdf},
  HAL_ID = {hal-01188725},
  HAL_VERSION = {v1},
}

@misc{unet,
  doi = {10.48550/ARXIV.1505.04597},
  
  url = {https://arxiv.org/abs/1505.04597},
  
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{mdx2021,
	doi = {10.3389/frsip.2021.808395},
  
	url = {https://doi.org/10.3389%2Ffrsip.2021.808395},
  
	year = 2022,
	month = {jan},
  
	publisher = {Frontiers Media {SA}
},
  
	volume = {1},
  
	author = {Yuki Mitsufuji and Giorgio Fabbro and Stefan Uhlich and Fabian-Robert Stöter and Alexandre D{\'{e}}fossez and Minseok Kim and Woosung Choi and Chin-Yun Yu and Kin-Wai Cheuk},
  
	title = {Music Demixing Challenge 2021},
  
	journal = {Frontiers in Signal Processing}
}

@article{transformer,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {CoRR},
  volume    = {abs/1706.03762},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03762},
  eprinttype = {arXiv},
  eprint    = {1706.03762},
  timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{2Dpe,
    title={Translating Math Formula Images to LaTeX Sequences Using Deep Neural Networks with Sequence-level Training},
    author={Zelun Wang and Jyh-Charn Liu},
    year={2019},
    eprint={1908.11415},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{adam,
  doi = {10.48550/ARXIV.1412.6980},
  
  url = {https://arxiv.org/abs/1412.6980},
  
  author = {Kingma, Diederik P. and Ba, Jimmy},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Adam: A Method for Stochastic Optimization},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{brown2020language,
    title={Language Models are Few-Shot Learners},
    author={Tom B. Brown et al.},
    year={2020},
    eprint={2005.14165},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@InProceedings{Rombach_2022_CVPR,
        author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\"orn},
        title     = {High-Resolution Image Synthesis With Latent Diffusion Models},
        booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
        month     = {June},
        year      = {2022},
        pages     = {10684-10695}
    }
    
@article{convtasnet,
  title={Conv-TasNet: Surpassing Ideal Time--Frequency Magnitude Masking for Speech Separation},
  author={Luo, Yi and Mesgarani, Nima},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2019},
  publisher={IEEE}
}

@article{umx,
  author={F.-R. St\"oter and S. Uhlich and A. Liutkus and Y. Mitsufuji},
  title={Open-Unmix - A Reference Implementation for Music Source Separation},
  journal={Journal of Open Source Software},
  year=2019,
  doi = {10.21105/joss.01667},
}

@article{xumx,
  title={All for One and One for All: Improving Music Separation by Bridging Networks},
  author={Ryosuke Sawata and Stefan Uhlich and Shusuke Takahashi and Yuki Mitsufuji},
  year={2020},
  eprint={2010.04228},
  archivePrefix={arXiv},
  primaryClass={eess.AS}
}

@inproceedings{lasaft,
  title={LaSAFT: Latent Source Attentive Frequency Transformation for Conditioned Source Separation},
  author={Choi, Woosung and Kim, Minseok and Chung, Jaehwa and Jung, Soonyoung},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2021},
}

@article{waveunet,
  title={Wave-U-Net: A Multi-Scale Neural Network for End-to-End Audio Source Separation},
  author={Daniel Stoller and Sebastian Ewert and Simon Dixon},
  year={2018},
  journal={arXiv preprint arXiv:1806.03185},
}

@inproceedings{luo2020dual,
  title={Dual-path rnn: efficient long sequence modeling for time-domain single-channel speech separation},
  author={Luo, Yi and Chen, Zhuo and Yoshioka, Takuya},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={46--50},
  year={2020},
  organization={IEEE}
}

@inproceedings{subakan2021attention,
  title={Attention is all you need in speech separation},
  author={Subakan, Cem and Ravanelli, Mirco and Cornell, Samuele and Bronzi, Mirko and Zhong, Jianyuan},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={21--25},
  year={2021},
  organization={IEEE}
}

@Misc{xFormers2021,
  author =       {Benjamin Lefaudeux and Francisco Massa and Diana Liskovich and Wenhan Xiong and Vittorio Caggiano and Sean Naren and Min Xu and Jieru Hu and Marta Tintore and Susan Zhang},
  title =        {xFormers: A modular and hackable Transformer modelling library},
  howpublished = {\url{https://github.com/facebookresearch/xformers}},
  year =         {2021}
}